---
title: "MMA 865 Final Project"
output: html_document
date: "Summer 2017"
author: "Team Colborne"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r libraries}
library(tidyverse)
library(sparklyr)
```



Connect to the spark cluster.

```{r}
config <- spark_config() 
config$'sparklyr.shell.executor-memory' <- "20g" 
config$'sparklyr.shell.driver-memory' <- "10g" 
config$spark.yarn.am.memory <- "15g"

# Full list of config options: https://spark.apache.org/docs/2.0.1/running-on-yarn.html

sc <- spark_connect(master = "yarn-client", spark_home = "/usr/hdp/current/spark2-client/", config=config)
```

# Read in the data

I've put a copy of all the files on HDFS, so we can load the data directory from there.
(Rather than loading it into R's memory and using copy_to() to move it into Hadoop's memory.)

Now, the `in_path` below does not point a directory on the local filesystem, but rather to a directory on HDFS.

I've created the directories in HDFS so that they have the same structure as the local filesystem, to avoid unnecessary confusion.

```{r}
in_path = 'hdfs:///user/hpc3552/scene-csv/sample03/clean/'

scene_mbr_dim <- spark_read_csv(sc, name='scene_mbr_dim', path=paste(in_path, 'scene_mbr_dim.csv', sep=""), header = TRUE, delimiter = ",")
head(scene_mbr_dim, n=10)

scene_mbr_acct_dim <- spark_read_csv(sc, name='scene_mbr_acct_dim', path=paste(in_path, 'scene_mbr_acct_dim.csv', sep=""), header = TRUE, delimiter = ",")
head(scene_mbr_acct_dim, n=10)
dim(scene_mbr_acct_dim)

scene_pt_fact <- spark_read_csv(sc, name='scene_pt_fact', path=paste(in_path, 'scene_pt_fact.csv', sep=""), header = TRUE, delimiter = ",")
dim(scene_pt_fact)
head(scene_pt_fact, n=10)

```
Rows and Columns of scene_mbr_dim
```{r}
dim(scene_mbr_dim)  
```

Rows and Columns of scene_mbr_acct_dim
```{r}
dim(scene_mbr_acct_dim)  
```

Rows and Columns of scene_pt_fact
```{r}
dim(scene_pt_fact)  
colnames(scene_pt_fact)
```
## Combine Data i.e. join files
```{r}

scene_data <- left_join(x = scene_mbr_dim, y = scene_pt_fact, by = "scene_mbr_key")
head(scene_data)
colnames(scene_data)
summary(scene_data)
dim(scene_data)

#spark_write_parquet(scene_data, "hdfs:///user/sa100006/scene-csv/sample03/clean/")
```

## Analyze

Now, go forth and use `sparklyr`. For manipulating data, use the same `dplyr` commands (e.g., `filter`, 'group_by`, etc.) that you're used to, and spark will do the right thing. (That is, spark will translate the `dplyr` command into a series of MapReduce jobs under the hood!) For machine learning, use the `sparklyr` `ml_*` commands, e.g., `ml_decision_tree`, `ml_naive_bayes`, etc.

Good luck, grasshopper.

##Taking sample of sample
```{r}
scene_data_small <- sample_frac(scene_data, 0.01)
#Taking sample of sample
dim(scene_data_small)
scene_data_r <- collect(scene_data_small)
str(scene_data_r)
colnames(scene_data_r)
```

##Feature Engineering
```{r}

#Converting Characters variables into Factors

#Definition of Month Factor, it's an Ordinal factor therefore sequence matter
month_levels <- c(
  "January", "February", "March", "April", "May", "June", 
  "July", "August", "September", "October", "November", "December"
)

#Postal Code Factor
scene_data_r$psnl_post_cd_f <- as.factor(scene_data_r$psnl_post_cd)
sort(unique(scene_data_r$psnl_post_cd_f))

#Province Factor
scene_data_r$psnl_prov_state_cd_f <- as.factor(scene_data_r$psnl_prov_state_cd)
sort(unique(scene_data_r$psnl_prov_state_cd_f))

#City Factor
scene_data_r$psnl_city_f <- as.factor(scene_data_r$psnl_city)
sort(unique(scene_data_r$psnl_city_f))

#Suspended Flag Factor
scene_data_r$suspended_f_f <- as.factor(scene_data_r$suspended_f)
sort(unique(scene_data_r$suspended_f_f))
count(scene_data_r,suspended_f)

#Gender Factor
scene_data_r$gndr_desc_f <- as.factor(scene_data_r$gndr_desc)
sort(unique(scene_data_r$gndr_desc_f))
count(scene_data_r,gndr_desc_f)

#Preferred Location Factor
scene_data_r$prefrd_loctn_desc_f <- as.factor(scene_data_r$prefrd_loctn_desc)
sort(unique(scene_data_r$prefrd_loctn_desc_f))
count(scene_data_r,prefrd_loctn_desc_f)

#Email preference Factor
scene_data_r$email_prefnc_desc_f <- as.factor(scene_data_r$email_prefnc_desc)
sort(unique(scene_data_r$email_prefnc_desc_f))
count(scene_data_r,email_prefnc_desc_f)

#Education Level Factor
scene_data_r$ed_lvl_desc_f <- as.factor(scene_data_r$ed_lvl_desc)
sort(unique(scene_data_r$ed_lvl_desc_f))
count(scene_data_r,ed_lvl_desc_f)

#Preferred Time Show Factor
#Definition of Time Factor, it's an Ordinal factor therefore sequence matter
time_level <- c("1:00pm", "2:00pm", "3:00pm", "4:00pm", "5:00pm", "6:00pm", "7:00pm", "8:00pm", "9:00pm", "10:00pm", "11:00pm", "12:00am")

scene_data_r$prefrd_show_tm_desc[scene_data_r$prefrd_show_tm_desc == "12 midnight" ] <- "12:00am" 

scene_data_r$prefrd_show_tm_desc_f <- factor(scene_data_r$prefrd_show_tm_desc, levels = time_level)
sort(unique(scene_data_r$prefrd_show_tm_desc_f))
count(scene_data_r,prefrd_show_tm_desc_f)

#Number of People in HH Factor
#Definition of people in HH factor, it's an Ordinal factor therefore sequence matter
hh_member_level = c("1","2","3","4","5","6+")
scene_data_r$num_of_hh_pple_desc_f <- factor(scene_data_r$num_of_hh_pple_desc, levels = hh_member_level)
sort(unique(scene_data_r$num_of_hh_pple_desc_f))
count(scene_data_r,num_of_hh_pple_desc_f)

#Movie Watching Frequency Factor
#Movie Watching Frequency factor, it's an Ordinal factor therefore sequence matter
movie_frequency_level = c("<2","3-6","7-10","11-20","20+")
scene_data_r$movie_gng_frq_ref_desc_f <- factor(scene_data_r$movie_gng_frq_ref_desc, levels = movie_frequency_level)
sort(unique(scene_data_r$movie_gng_frq_ref_desc_f))
count(scene_data_r,num_of_hh_pple_desc_f)

#Marital Status Factor
scene_data_r$mrtl_stat_desc_f <- as.factor(scene_data_r$mrtl_stat_desc)
sort(unique(scene_data_r$mrtl_stat_desc_f))
count(scene_data_r,mrtl_stat_desc_f)

#Language Factor
scene_data_r$lang_desc_f <- as.factor(scene_data_r$lang_desc)
sort(unique(scene_data_r$lang_desc_f))
count(scene_data_r,lang_desc_f)

#CD Factor
scene_data_r$cd_f <- as.factor(scene_data_r$cd)
sort(unique(scene_data_r$cd_f))
count(scene_data_r,cd_f)

#NM Factor
scene_data_r$nm_f <- as.factor(scene_data_r$nm)
sort(unique(scene_data_r$nm_f))
count(scene_data_r,cd_f)

#Transaction Source Factor
scene_data_r$txn_src_f <- as.factor(scene_data_r$txn_src)
sort(unique(scene_data_r$txn_src_f))
count(scene_data_r,txn_src_f)

#Transaction Source 1 Factor
scene_data_r$txn_tp_1_f <- as.factor(scene_data_r$txn_tp_1)
sort(unique(scene_data_r$txn_tp_1_f))
count(scene_data_r,txn_tp_1_f)

#Transaction Source 2 Factor
scene_data_r$txn_tp_2_f <- as.factor(scene_data_r$txn_tp_2)
sort(unique(scene_data_r$txn_tp_2_f))
count(scene_data_r,txn_tp_2_f)

#Transaction Source 3 Factor
scene_data_r$txn_tp_3_f <- as.factor(scene_data_r$txn_tp_3)
sort(unique(scene_data_r$txn_tp_3_f))
count(scene_data_r,txn_tp_3_f)

#Month Factor
scene_data_r$mo_clndr_code_f <- factor(scene_data_r$mo_clndr_code, levels = month_levels)
sort(unique(scene_data_r$mo_clndr_code_f))
count(scene_data_r,mo_clndr_code_f)

group_by(scene_data_r, mrtl_stat_desc_f)%>%
summarise(count=n(), percentage = n()/nrow(scene_mbr_dim))%>%
arrange(desc(count))

rm(list=ls())
library(tidyverse)
library(data.table)
library(sparklyr)
library(rsparkling)
library(h2o)

sc <- spark_connect("local")

h2o.init()

#R script
in_path_r = 'C:/R_WD/865/'

scene_mbr_dim <-fread(paste(in_path_r, 'scene_mbr_dim.csv', sep=""), sep=",")
scene_mbr_acct_dim <-fread(paste(in_path_r, 'scene_mbr_acct_dim.csv', sep=""), sep=",")
scene_pt_fact <-fread(paste(in_path_r, 'scene_pt_fact.csv', sep=""), sep=",")

colnames(scene_pt_fact)

get_month <- function(name){
  case_when(
    name == "January" ~ 1,
    name == "February" ~ 2,
    name == "March" ~ 3,
    name == "April" ~ 4,
    name == "May" ~ 5,
    name == "June" ~ 6,
    name == "July" ~ 7,
    name == "August" ~ 8,
    name == "September" ~ 9,
    name == "October" ~ 10,
    name == "November" ~ 11,
    name == "December" ~ 12
  )
}

years <- c(2007:2016)
months <- c(1:12)

for (year in years){
  for (month in months){
    x <- cbind(year,month)
    year_months <- rbind(year_months, x)
  }
}

mem <- scene_mbr_dim %>%
      

year_months

test2<- scene_pt_fact %>%
        filter(txn_amt > 0 & txn_amt <= 10000)  %>%
        mutate(month_code = get_month(name = mo_clndr_code))  %>% 
        arrange(scene_mbr_key,anul_clndr_code,month_code) %>% 
        mutate(lag1=lag(txn_amt),lag2=lag(txn_amt,2),movave=(lag1+lag2)/2) %>%
        select(scene_mbr_key,anul_clndr_code,mo_clndr_code,month_code,txn_amt,lag1,lag2,movave)


```

## Disconnect from Spark

```{r}
spark_disconnect(sc)
```
